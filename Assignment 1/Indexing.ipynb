{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcuEHtGFoOqt"
   },
   "source": [
    "# Indexing Excercise \n",
    "\n",
    "This exercise has two parts: \n",
    "\n",
    "- In part 1, we are going to index the [MS MARCO](http://www.msmarco.org/) passage collection Pyserini toolkit and explore some features of the index. For this part, you only need to run code and understand it. You will be using the index and code snippets in the next assignment.\n",
    "\n",
    "- In part 2, we are going to write a code for generating an inverted index and index part of MS MARCO collection. For this part, you need to first run the first part (1.1 and 1.2) to build the environment and prepare the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egQ3UlHWpj0K"
   },
   "source": [
    "## PART 1: Generate the index via Pyserini\n",
    "\n",
    "We use [Anserini](https://github.com/castorini/anserini]) toolkit and its python interface [Pyserini](https://github.com/castorini/pyserini)  to run our experiments. \n",
    "\n",
    "***This part is created based on Anserini/Pyserini tutorials. You can learn more by checking their repositories and tutorials.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Setup the environment\n",
    "\n",
    "Install Pyserini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyserini\n",
      "  Obtaining dependency information for pyserini from https://files.pythonhosted.org/packages/bc/e8/adeba14e4c8d2e2cb26089337fb94c40116ffd73db19f24cc9fd13c1d47c/pyserini-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading pyserini-0.22.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting Cython>=0.29.21 (from pyserini)\n",
      "  Obtaining dependency information for Cython>=0.29.21 from https://files.pythonhosted.org/packages/e8/1a/26113a7a220b360a13f1a060deb1461bf55d433673dc79e523b6648ccc2d/Cython-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading Cython-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /home/codespace/.local/lib/python3.10/site-packages (from pyserini) (1.25.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from pyserini) (2.1.0)\n",
      "Collecting pyjnius>=1.4.0 (from pyserini)\n",
      "  Obtaining dependency information for pyjnius>=1.4.0 from https://files.pythonhosted.org/packages/62/c9/6ae043600ddeae09376fe60c09d1b39265991f811bdab58a9218c3aab6ae/pyjnius-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pyjnius-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /home/codespace/.local/lib/python3.10/site-packages (from pyserini) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/codespace/.local/lib/python3.10/site-packages (from pyserini) (1.11.2)\n",
      "Collecting tqdm (from pyserini)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers>=4.6.0 (from pyserini)\n",
      "  Obtaining dependency information for transformers>=4.6.0 from https://files.pythonhosted.org/packages/13/30/54b59e73400df3de506ad8630284e9fd63f4b94f735423d55fc342181037/transformers-4.33.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.33.1-py3-none-any.whl.metadata (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece>=0.1.95 (from pyserini)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nmslib>=2.1.1 (from pyserini)\n",
      "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting onnxruntime>=1.8.1 (from pyserini)\n",
      "  Obtaining dependency information for onnxruntime>=1.8.1 from https://files.pythonhosted.org/packages/2f/e2/ced4e64433097cb14425098ce3c6200b83d226005e8c23ba5bac44c89ab9/onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting lightgbm>=3.3.2 (from pyserini)\n",
      "  Obtaining dependency information for lightgbm>=3.3.2 from https://files.pythonhosted.org/packages/f6/9d/fae632fd823b407448b9cd2b28288172c040415e2c9ab401cca9e67b4192/lightgbm-4.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading lightgbm-4.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Collecting spacy>=3.2.1 (from pyserini)\n",
      "  Obtaining dependency information for spacy>=3.2.1 from https://files.pythonhosted.org/packages/58/93/051fc55f3e4e6d0d97beb77bbd5cd9e17589a0092305b4ae6164c6dcb58a/spacy-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading spacy-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.10/site-packages (from pyserini) (6.0.1)\n",
      "Collecting pybind11<2.6.2 (from nmslib>=2.1.1->pyserini)\n",
      "  Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from nmslib>=2.1.1->pyserini) (5.9.5)\n",
      "Collecting coloredlogs (from onnxruntime>=1.8.1->pyserini)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m731.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers (from onnxruntime>=1.8.1->pyserini)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from onnxruntime>=1.8.1->pyserini) (23.1)\n",
      "Collecting protobuf (from onnxruntime>=1.8.1->pyserini)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/bb/c3/6a06208ecf0934ecaf509b51c52a6cf688586f54ae81ac65c56124571494/protobuf-4.24.3-cp37-abi3-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading protobuf-4.24.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from onnxruntime>=1.8.1->pyserini) (1.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.4.0->pyserini) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.4.0->pyserini) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.4.0->pyserini) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.22.1->pyserini) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.22.1->pyserini) (3.2.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy>=3.2.1->pyserini)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy>=3.2.1->pyserini)\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=3.2.1->pyserini)\n",
      "  Downloading murmurhash-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=3.2.1->pyserini)\n",
      "  Downloading cymem-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy>=3.2.1->pyserini)\n",
      "  Downloading preshed-3.0.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting thinc<8.2.0,>=8.1.8 (from spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for thinc<8.2.0,>=8.1.8 from https://files.pythonhosted.org/packages/d7/fc/2ea1a37a60ad1c7b9f41699ccd29170f6d479d3349e6742503278b4bc811/thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/49/bf/4ea90444abfd1cf12f71ec74b8f95bea5d983145e58001bc022d40151ff4/srsly-2.4.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading srsly-2.4.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/45/8f/5b73efc14e0373d9bb0de6ce1ab04a8f77420dc473f1f3ef270caf085cff/catalogue-2.0.9-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.9-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy>=3.2.1->pyserini)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pathy>=0.10.0 (from spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for pathy>=0.10.0 from https://files.pythonhosted.org/packages/b5/c3/04a002ace658133f5ac48d30258ed9ceab720595dc1ac36df02fe52018af/pathy-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading pathy-0.10.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for smart-open<7.0.0,>=5.2.1 from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from spacy>=3.2.1->pyserini) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/82/06/fafdc75e48b248eff364b4249af4bcc6952225e8f20e8205820afc66e88e/pydantic-2.3.0-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.3.0-py3-none-any.whl.metadata (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from spacy>=3.2.1->pyserini) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from spacy>=3.2.1->pyserini) (68.0.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy>=3.2.1->pyserini)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from transformers>=4.6.0->pyserini) (3.12.3)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers>=4.6.0->pyserini)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.15.1 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.6.0->pyserini)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/d1/df/460ca6171a8494fcf37af43f52f6fac23e38784bb4a26563f6fa01ef6faf/regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.6.0->pyserini)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.6.0->pyserini)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/6c/f0/c17bbdb1e5f9dab29d44cade445135789f75f8f08ea2728d04493ea8412b/safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.15.1->transformers>=4.6.0->pyserini)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/3a/9f/b40e8e5be886143379000af5fc0c675352d59e82fd869d24bf784161dc77/fsspec-2023.9.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.9.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=4.6.0->pyserini) (4.7.1)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/d8/f0/a2ee543a96cc624c35a9086f39b1ed2aa403c6d355dfe47a11ee5c64a164/annotated_types-0.5.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic-core==2.6.3 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for pydantic-core==2.6.3 from https://files.pythonhosted.org/packages/fc/dc/2443b6224c396b765d2c68d61a8c24eeb05a6b425518cad80ce1fc4d4430/pydantic_core-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->pyserini) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2023.7.22)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.2.0,>=8.1.8->spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/0a/db/223c5b780d1d8eb3ba5263f8c2c6a42502a17702917731f9ca68c4358bfd/blis-0.7.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading blis-0.7.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.2.0,>=8.1.8->spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/ce/a3/21634c476fd55f06f5c31876985da59024fab75a537b0398aa4039e4e730/confection-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer<0.10.0,>=0.3.0->spacy>=3.2.1->pyserini)\n",
      "  Obtaining dependency information for click<9.0.0,>=7.1.1 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.8.1->pyserini)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->spacy>=3.2.1->pyserini) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.3.0)\n",
      "Downloading pyserini-0.22.0-py3-none-any.whl (140.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.5/140.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Cython-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightgbm-4.0.0-py3-none-manylinux_2_28_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyjnius-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.9-py3-none-any.whl (17 kB)\n",
      "Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.3.0-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading srsly-2.4.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading protobuf-4.24.3-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Downloading blis-0.7.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.2-py3-none-any.whl (34 kB)\n",
      "Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: nmslib\n",
      "  Building wheel for nmslib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nmslib: filename=nmslib-2.1.1-cp310-cp310-linux_x86_64.whl size=13569302 sha256=5503b636aedb2e58abaa8a73537a3d66e946b4327189a21ce9eca4d1c0e3e492\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/21/1a/5d/4cc754a5b1a88405cad184b76f823897a63a8d19afcd4b9314\n",
      "Successfully built nmslib\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, pyjnius, flatbuffers, cymem, wasabi, tqdm, spacy-loggers, spacy-legacy, smart-open, regex, pydantic-core, pybind11, protobuf, murmurhash, langcodes, humanfriendly, fsspec, Cython, click, catalogue, blis, annotated-types, typer, srsly, pydantic, preshed, nmslib, lightgbm, huggingface-hub, coloredlogs, transformers, pathy, onnxruntime, confection, thinc, spacy, pyserini\n",
      "Successfully installed Cython-3.0.2 annotated-types-0.5.0 blis-0.7.10 catalogue-2.0.9 click-8.1.7 coloredlogs-15.0.1 confection-0.1.2 cymem-2.0.7 flatbuffers-23.5.26 fsspec-2023.9.0 huggingface-hub-0.16.4 humanfriendly-10.0 langcodes-3.3.0 lightgbm-4.0.0 murmurhash-1.0.9 nmslib-2.1.1 onnxruntime-1.15.1 pathy-0.10.2 preshed-3.0.8 protobuf-4.24.3 pybind11-2.6.1 pydantic-2.3.0 pydantic-core-2.6.3 pyjnius-1.5.0 pyserini-0.22.0 regex-2023.8.8 safetensors-0.3.3 sentencepiece-0.1.99 smart-open-6.4.0 spacy-3.6.1 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.7 thinc-8.1.12 tokenizers-0.13.3 tqdm-4.66.1 transformers-4.33.1 typer-0.9.0 wasabi-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyserini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuqRujlSfnTS"
   },
   "source": [
    "Clone the Anserini repository from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'anserini'...\n",
      "remote: Enumerating objects: 29354, done.\u001b[K\n",
      "remote: Counting objects: 100% (3672/3672), done.\u001b[K\n",
      "remote: Compressing objects: 100% (959/959), done.\u001b[K\n",
      "remote: Total 29354 (delta 3146), reused 3059 (delta 2634), pack-reused 25682\u001b[K\n",
      "Receiving objects: 100% (29354/29354), 85.32 MiB | 19.19 MiB/s, done.\n",
      "Resolving deltas: 100% (19795/19795), done.\n",
      "Note: switching to 'ad5ba1c76196436f8a0e28efdb69960d4873efe3'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at ad5ba1c7 Release notes for v0.9.2 (#1197)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/castorini/anserini.git\n",
    "!cd anserini && git checkout ad5ba1c76196436f8a0e28efdb69960d4873efe3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcU5a-ETrqnT"
   },
   "source": [
    "### 1.2 Get the collection and prepare the files\n",
    "MS MARCO (MicroSoft MAchine Reading COmprehension) is a large-scale dataset that defines many tasks from question answering to ranking. Here we focus on the collection designed for passage re-ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-08 13:48:10--  https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz\n",
      "Resolving msmarco.blob.core.windows.net (msmarco.blob.core.windows.net)... 20.150.34.4\n",
      "Connecting to msmarco.blob.core.windows.net (msmarco.blob.core.windows.net)|20.150.34.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1035009698 (987M) [application/octet-stream]\n",
      "Saving to: ‘data/msmarco_passage/collection.tar.gz’\n",
      "\n",
      "collection.tar.gz   100%[===================>] 987.06M  12.9MB/s    in 76s     \n",
      "\n",
      "2023-09-08 13:49:26 (13.0 MB/s) - ‘data/msmarco_passage/collection.tar.gz’ saved [1035009698/1035009698]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz -P data/msmarco_passage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection.tar.gz\n",
      "collection.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls data/msmarco_passage/ \n",
    "!tar xvfz data/msmarco_passage/collection.tar.gz -C data/msmarco_passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtK9rHMOwjYx"
   },
   "source": [
    "The original MS MARCO collection is a tab-separated values (TSV) file. We need to convert the collection into the jsonl format that can be processed by Anserini. jsonl files contain JSON object per line.\n",
    "\n",
    "This command generates 9 jsonl files in your data/msmarco_passage/collection_jsonl directory, each with 1M lines (except for the last one, which should have 841,823 lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting collection...\n",
      "Converted 0 docs in 1 files\n",
      "Converted 100000 docs in 1 files\n",
      "Converted 200000 docs in 1 files\n",
      "Converted 300000 docs in 1 files\n",
      "Converted 400000 docs in 1 files\n",
      "Converted 500000 docs in 1 files\n",
      "Converted 600000 docs in 1 files\n",
      "Converted 700000 docs in 1 files\n",
      "Converted 800000 docs in 1 files\n",
      "Converted 900000 docs in 1 files\n",
      "Converted 1000000 docs in 2 files\n",
      "Converted 1100000 docs in 2 files\n",
      "Converted 1200000 docs in 2 files\n",
      "Converted 1300000 docs in 2 files\n",
      "Converted 1400000 docs in 2 files\n",
      "Converted 1500000 docs in 2 files\n",
      "Converted 1600000 docs in 2 files\n",
      "Converted 1700000 docs in 2 files\n",
      "Converted 1800000 docs in 2 files\n",
      "Converted 1900000 docs in 2 files\n",
      "Converted 2000000 docs in 3 files\n",
      "Converted 2100000 docs in 3 files\n",
      "Converted 2200000 docs in 3 files\n",
      "Converted 2300000 docs in 3 files\n",
      "Converted 2400000 docs in 3 files\n",
      "Converted 2500000 docs in 3 files\n",
      "Converted 2600000 docs in 3 files\n",
      "Converted 2700000 docs in 3 files\n",
      "Converted 2800000 docs in 3 files\n",
      "Converted 2900000 docs in 3 files\n",
      "Converted 3000000 docs in 4 files\n",
      "Converted 3100000 docs in 4 files\n",
      "Converted 3200000 docs in 4 files\n",
      "Converted 3300000 docs in 4 files\n",
      "Converted 3400000 docs in 4 files\n",
      "Converted 3500000 docs in 4 files\n",
      "Converted 3600000 docs in 4 files\n",
      "Converted 3700000 docs in 4 files\n",
      "Converted 3800000 docs in 4 files\n",
      "Converted 3900000 docs in 4 files\n",
      "Converted 4000000 docs in 5 files\n",
      "Converted 4100000 docs in 5 files\n",
      "Converted 4200000 docs in 5 files\n",
      "Converted 4300000 docs in 5 files\n",
      "Converted 4400000 docs in 5 files\n",
      "Converted 4500000 docs in 5 files\n",
      "Converted 4600000 docs in 5 files\n",
      "Converted 4700000 docs in 5 files\n",
      "Converted 4800000 docs in 5 files\n",
      "Converted 4900000 docs in 5 files\n",
      "Converted 5000000 docs in 6 files\n",
      "Converted 5100000 docs in 6 files\n",
      "Converted 5200000 docs in 6 files\n",
      "Converted 5300000 docs in 6 files\n",
      "Converted 5400000 docs in 6 files\n",
      "Converted 5500000 docs in 6 files\n",
      "Converted 5600000 docs in 6 files\n",
      "Converted 5700000 docs in 6 files\n",
      "Converted 5800000 docs in 6 files\n",
      "Converted 5900000 docs in 6 files\n",
      "Converted 6000000 docs in 7 files\n",
      "Converted 6100000 docs in 7 files\n",
      "Converted 6200000 docs in 7 files\n",
      "Converted 6300000 docs in 7 files\n",
      "Converted 6400000 docs in 7 files\n",
      "Converted 6500000 docs in 7 files\n",
      "Converted 6600000 docs in 7 files\n",
      "Converted 6700000 docs in 7 files\n",
      "Converted 6800000 docs in 7 files\n",
      "Converted 6900000 docs in 7 files\n",
      "Converted 7000000 docs in 8 files\n",
      "Converted 7100000 docs in 8 files\n",
      "Converted 7200000 docs in 8 files\n",
      "Converted 7300000 docs in 8 files\n",
      "Converted 7400000 docs in 8 files\n",
      "Converted 7500000 docs in 8 files\n",
      "Converted 7600000 docs in 8 files\n",
      "Converted 7700000 docs in 8 files\n",
      "Converted 7800000 docs in 8 files\n",
      "Converted 7900000 docs in 8 files\n",
      "Converted 8000000 docs in 9 files\n",
      "Converted 8100000 docs in 9 files\n",
      "Converted 8200000 docs in 9 files\n",
      "Converted 8300000 docs in 9 files\n",
      "Converted 8400000 docs in 9 files\n",
      "Converted 8500000 docs in 9 files\n",
      "Converted 8600000 docs in 9 files\n",
      "Converted 8700000 docs in 9 files\n",
      "Converted 8800000 docs in 9 files\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!cd anserini && python ./src/main/python/msmarco/convert_collection_to_jsonl.py \\\n",
    " --collection_path ../data/msmarco_passage/collection.tsv --output_folder ../data/msmarco_passage/collection_jsonl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDXFZHf_5lR-"
   },
   "source": [
    "**Check the data!**\n",
    "\n",
    "jsonl files are JSON files with keys id and contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1000000 data/msmarco_passage/collection_jsonl/docs00.json\n",
      "   1000000 data/msmarco_passage/collection_jsonl/docs01.json\n",
      "   1000000 data/msmarco_passage/collection_jsonl/docs02.json\n",
      "   1000000 data/msmarco_passage/collection_jsonl/docs03.json\n",
      "   1000000 data/msmarco_passage/collection_jsonl/docs04.json\n",
      "   1000000 data/msmarco_passage/collection_jsonl/docs05.json\n",
      "   1000000 data/msmarco_passage/collection_jsonl/docs06.json\n",
      "   1000000 data/msmarco_passage/collection_jsonl/docs07.json\n",
      "    841823 data/msmarco_passage/collection_jsonl/docs08.json\n",
      "   8841823 total\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/msmarco_passage/collection_jsonl/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"0\", \"contents\": \"The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.\"}\n",
      "{\"id\": \"1\", \"contents\": \"The Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.\"}\n",
      "{\"id\": \"2\", \"contents\": \"Essay on The Manhattan Project - The Manhattan Project The Manhattan Project was to see if making an atomic bomb possible. The success of this project would forever change the world forever making it known that something this powerful can be manmade.\"}\n",
      "{\"id\": \"3\", \"contents\": \"The Manhattan Project was the name for a project conducted during World War II, to develop the first atomic bomb. It refers specifically to the period of the project from 194 \\u00e2\\u0080\\u00a6 2-1946 under the control of the U.S. Army Corps of Engineers, under the administration of General Leslie R. Groves.\"}\n",
      "{\"id\": \"4\", \"contents\": \"versions of each volume as well as complementary websites. The first website\\u00e2\\u0080\\u0093The Manhattan Project: An Interactive History\\u00e2\\u0080\\u0093is available on the Office of History and Heritage Resources website, http://www.cfo. doe.gov/me70/history. The Office of History and Heritage Resources and the National Nuclear Security\"}\n"
     ]
    }
   ],
   "source": [
    "!head -5 data/msmarco_passage/collection_jsonl/docs00.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAu65qTQ6KNz"
   },
   "source": [
    "Remove the original files to make room for the index. \n",
    "Check the contents of `data/msmarco_passage` before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection.tar.gz  collection.tsv  collection_jsonl\n",
      "collection.tar.gz  collection_jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls data/msmarco_passage\n",
    "!rm data/msmarco_passage/*.tsv\n",
    "!ls data/msmarco_passage\n",
    "!rm -rf sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf4Kxgpq6vna"
   },
   "source": [
    "### 1.3 Generate the index using Pyserini\n",
    "\n",
    "\n",
    "Here are some common indexing options with Pyserini (for more options, check Pyserini documentation):\n",
    "\n",
    "```\n",
    "* input: Path to collection\n",
    "* threads: Number of threads to run\n",
    "* collection: Type of Anserini Collection, e.g., LuceneDocumentGenerator, TweetGenerator (subclass of LuceneDocumentGenerator for TREC Microblog)\n",
    "* index: Path to index output\n",
    "* storePositions: Boolean flag to store positions\n",
    "* storeDocvectors: Boolean flag to store document vectors\n",
    "* storeRawDocs: Boolean flag to store raw document text\n",
    "* keepStopwords: Boolean flag to keep stopwords (False by default)\n",
    "* stemmer: Stemmer to use (Porter by default)\n",
    "```\n",
    "\n",
    "We now have everything in place to index the collection. **The indexing speed may vary, the process may take about 10 minutes (or more) in Google Colab.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyserini.index is deprecated, please use pyserini.index.lucene.\n",
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2023-09-08 13:57:01,779 INFO  [main] index.IndexCollection (IndexCollection.java:380) - Setting log level to INFO\n",
      "2023-09-08 13:57:01,780 INFO  [main] index.IndexCollection (IndexCollection.java:383) - Starting indexer...\n",
      "2023-09-08 13:57:01,781 INFO  [main] index.IndexCollection (IndexCollection.java:384) - ============ Loading Parameters ============\n",
      "2023-09-08 13:57:01,781 INFO  [main] index.IndexCollection (IndexCollection.java:385) - DocumentCollection path: data/msmarco_passage/collection_jsonl\n",
      "2023-09-08 13:57:01,781 INFO  [main] index.IndexCollection (IndexCollection.java:386) - CollectionClass: JsonCollection\n",
      "2023-09-08 13:57:01,781 INFO  [main] index.IndexCollection (IndexCollection.java:387) - Generator: DefaultLuceneDocumentGenerator\n",
      "2023-09-08 13:57:01,782 INFO  [main] index.IndexCollection (IndexCollection.java:388) - Threads: 9\n",
      "2023-09-08 13:57:01,782 INFO  [main] index.IndexCollection (IndexCollection.java:389) - Language: en\n",
      "2023-09-08 13:57:01,782 INFO  [main] index.IndexCollection (IndexCollection.java:390) - Stemmer: porter\n",
      "2023-09-08 13:57:01,783 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Keep stopwords? false\n",
      "2023-09-08 13:57:01,783 INFO  [main] index.IndexCollection (IndexCollection.java:392) - Stopwords: null\n",
      "2023-09-08 13:57:01,783 INFO  [main] index.IndexCollection (IndexCollection.java:393) - Store positions? true\n",
      "2023-09-08 13:57:01,783 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Store docvectors? true\n",
      "2023-09-08 13:57:01,784 INFO  [main] index.IndexCollection (IndexCollection.java:395) - Store document \"contents\" field? false\n",
      "2023-09-08 13:57:01,784 INFO  [main] index.IndexCollection (IndexCollection.java:396) - Store document \"raw\" field? true\n",
      "2023-09-08 13:57:01,784 INFO  [main] index.IndexCollection (IndexCollection.java:397) - Additional fields to index: []\n",
      "2023-09-08 13:57:01,784 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Optimize (merge segments)? false\n",
      "2023-09-08 13:57:01,784 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Whitelist: null\n",
      "2023-09-08 13:57:01,785 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Pretokenized?: false\n",
      "2023-09-08 13:57:01,785 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Index path: indexes/lucene-index-msmarco-passage\n",
      "2023-09-08 13:57:01,795 INFO  [main] index.IndexCollection (IndexCollection.java:481) - ============ Indexing Collection ============\n",
      "2023-09-08 13:57:01,819 INFO  [main] index.IndexCollection (IndexCollection.java:468) - Using DefaultEnglishAnalyzer\n",
      "2023-09-08 13:57:01,819 INFO  [main] index.IndexCollection (IndexCollection.java:469) - Stemmer: porter\n",
      "2023-09-08 13:57:01,820 INFO  [main] index.IndexCollection (IndexCollection.java:470) - Keep stopwords? false\n",
      "2023-09-08 13:57:01,820 INFO  [main] index.IndexCollection (IndexCollection.java:471) - Stopwords file: null\n",
      "2023-09-08 13:57:02,017 INFO  [main] index.IndexCollection (IndexCollection.java:510) - Thread pool with 9 threads initialized.\n",
      "2023-09-08 13:57:02,018 INFO  [main] index.IndexCollection (IndexCollection.java:512) - Initializing collection in data/msmarco_passage/collection_jsonl\n",
      "2023-09-08 13:57:02,025 INFO  [main] index.IndexCollection (IndexCollection.java:521) - 9 files found\n",
      "2023-09-08 13:57:02,025 INFO  [main] index.IndexCollection (IndexCollection.java:522) - Starting to index...\n",
      "2023-09-08 13:58:02,091 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 0.00% of files completed, 740,000 documents indexed\n",
      "2023-09-08 13:59:02,092 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 0.00% of files completed, 2,130,000 documents indexed\n",
      "2023-09-08 14:00:02,098 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 0.00% of files completed, 3,580,000 documents indexed\n",
      "2023-09-08 14:01:02,100 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 0.00% of files completed, 5,040,000 documents indexed\n",
      "2023-09-08 14:02:02,100 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 0.00% of files completed, 6,410,000 documents indexed\n",
      "2023-09-08 14:02:48,320 DEBUG [pool-2-thread-9] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs08.json: 841823 docs added.\n",
      "2023-09-08 14:03:02,101 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 11.11% of files completed, 7,691,823 documents indexed\n",
      "2023-09-08 14:03:45,622 DEBUG [pool-2-thread-8] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs07.json: 1000000 docs added.\n",
      "2023-09-08 14:03:50,492 DEBUG [pool-2-thread-7] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs00.json: 1000000 docs added.\n",
      "2023-09-08 14:03:53,397 DEBUG [pool-2-thread-3] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs02.json: 1000000 docs added.\n",
      "2023-09-08 14:03:54,537 DEBUG [pool-2-thread-6] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs01.json: 1000000 docs added.\n",
      "2023-09-08 14:03:54,684 DEBUG [pool-2-thread-2] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs03.json: 1000000 docs added.\n",
      "2023-09-08 14:03:55,315 DEBUG [pool-2-thread-5] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs04.json: 1000000 docs added.\n",
      "2023-09-08 14:03:55,786 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs05.json: 1000000 docs added.\n",
      "2023-09-08 14:03:56,937 DEBUG [pool-2-thread-4] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs06.json: 1000000 docs added.\n",
      "2023-09-08 14:04:53,160 INFO  [main] index.IndexCollection (IndexCollection.java:578) - Indexing Complete! 8,841,823 documents indexed\n",
      "2023-09-08 14:04:53,160 INFO  [main] index.IndexCollection (IndexCollection.java:579) - ============ Final Counter Values ============\n",
      "2023-09-08 14:04:53,160 INFO  [main] index.IndexCollection (IndexCollection.java:580) - indexed:        8,841,823\n",
      "2023-09-08 14:04:53,161 INFO  [main] index.IndexCollection (IndexCollection.java:581) - unindexable:            0\n",
      "2023-09-08 14:04:53,161 INFO  [main] index.IndexCollection (IndexCollection.java:582) - empty:                  0\n",
      "2023-09-08 14:04:53,161 INFO  [main] index.IndexCollection (IndexCollection.java:583) - skipped:                0\n",
      "2023-09-08 14:04:53,162 INFO  [main] index.IndexCollection (IndexCollection.java:584) - errors:                 0\n",
      "2023-09-08 14:04:53,205 INFO  [main] index.IndexCollection (IndexCollection.java:587) - Total 8,841,823 documents indexed in 00:07:51\n"
     ]
    }
   ],
   "source": [
    "!python -m pyserini.index -collection JsonCollection -generator DefaultLuceneDocumentGenerator -threads 9 \\\n",
    "-input data/msmarco_passage/collection_jsonl -index indexes/lucene-index-msmarco-passage -storePositions -storeDocvectors -storeRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWl9RgbZ7dSv"
   },
   "source": [
    "Check the size of the index at the specified destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0_Nigxvr8DIK",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lucene-index-msmarco-passage\n",
      "4.1G\tindexes/lucene-index-msmarco-passage\n"
     ]
    }
   ],
   "source": [
    "!ls indexes\n",
    "!du -h indexes/lucene-index-msmarco-passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZMAtCEE-f0q"
   },
   "source": [
    "### 1.4 Explore Pyserini index\n",
    "\n",
    "We can now explore the index using the The IndexReader class of Pyserini. \n",
    "\n",
    "Read [Usage of the Index Reader API](https://github.com/castorini/pyserini/blob/master/docs/usage-indexreader.md) notebook for more information on accessing and manipulating an inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Pf0oDQfgp7l-"
   },
   "outputs": [],
   "source": [
    "from pyserini.index import IndexReader\n",
    "\n",
    "index_reader = IndexReader('indexes/lucene-index-msmarco-passage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bI2092DyZ94"
   },
   "source": [
    "Compute the collection and document frequencies of a term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed form of term \"plai\": df=155044, cf=200696\n"
     ]
    }
   ],
   "source": [
    "term = 'played'\n",
    "\n",
    "# Look up its document frequency (df) and collection frequency (cf).\n",
    "# Note, we use the unanalyzed form:\n",
    "df, cf = index_reader.get_term_counts(term)\n",
    "\n",
    "analyzed_form = index_reader.analyze(term)\n",
    "print(f'Analyzed form of term \"{analyzed_form[0]}\": df={df}, cf={cf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMwpOyMTulz2"
   },
   "source": [
    "Get basic index statistics of the index.\n",
    "\n",
    "Note that unless the underlying index was built with the `-optimize` option (i.e., merging all index segments into a single segment), unique_terms will show -1 (think what could be reason)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_terms': 352316036,\n",
       " 'documents': 8841823,\n",
       " 'non_empty_documents': 8841823,\n",
       " 'unique_terms': -1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_reader.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Generate the index yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Processing the text\n",
    "\n",
    "We need to process the text, which includes tokenization, stopword removal, and lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = ['a', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 'such', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']\n",
    "\n",
    "def process(text):\n",
    "    terms = []\n",
    "    # Remove special characters\n",
    "    chars = ['\\'', '.', ':', ',', '!', '?', '(', ')']\n",
    "    for ch in chars:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch, ' ')\n",
    "    \n",
    "    # Lowercasing and stopword removal\n",
    "    for term in text.split():\n",
    "        term = term.lower()\n",
    "        if term not in STOPWORDS:\n",
    "            terms.append(term)\n",
    "    return terms\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Complete the code for Inverted Index\n",
    "\n",
    "Implement the InvertedIndex class. \n",
    "\n",
    "Write the index to a file, where posting list of each term is presented in a line with this format: `Term1 docID1:freq1 docID2:freq2 ...`, e.g., \n",
    "\n",
    "```\n",
    "term1 1:1 4:2 5:1\n",
    "term2 2:1 \n",
    "term3 1:3 3:3 9:2\n",
    "...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QmSAgk2gQBdb"
   },
   "outputs": [],
   "source": [
    "class InvertedIndex(object):\n",
    "    def __init__(self):\n",
    "        self.index = {}\n",
    "\n",
    "    def add_posting(self, term:str, doc_id:int, count:int):\n",
    "        \"\"\"Adds a posting (term and Document ID) to the index.\"\"\"\n",
    "        # =======Your code=======\n",
    "        if term not in self.index:\n",
    "            self.index[term] = []\n",
    "        self.index[term].append((doc_id, count))\n",
    "        # =======================\n",
    "\n",
    "    def get_posting(self,term:str):\n",
    "        \"\"\"Returns the posting list of the term from the index.\"\"\"\n",
    "        # =======Your code=======\n",
    "        if term in self.index:\n",
    "            return self.index[term]\n",
    "        else:\n",
    "            return None\n",
    "        # =======================\n",
    "        \n",
    "    def get_dictionary(self):\n",
    "        \"\"\"Returns the dictionary of the index (unique terms in the index).\"\"\"\n",
    "        # =======Your code=======\n",
    "        return list(self.index.keys())   \n",
    "        # =======================\n",
    "    \n",
    "    def write_to_file(self, filename_index:str):\n",
    "        \"\"\"Writes the index to a textfile.\"\"\"\n",
    "        # =======Your code=======\n",
    "        with open(filename_index, 'w') as f:\n",
    "            for term, postings in self.index.items():\n",
    "                f.write(f\"{term} \")\n",
    "                for posting in postings:\n",
    "                    f.write(f\"{posting[0]}:{posting[1]} \")\n",
    "                f.write('\\n')\n",
    "        # ======================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this to test your code. If everything is correct, you should not get errors here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = InvertedIndex()\n",
    "index.add_posting(\"t1\", 1, 2)\n",
    "index.add_posting(\"t1\", 2, 1)\n",
    "index.add_posting(\"t2\", 2, 3)\n",
    "assert len(index.get_dictionary()) == 2\n",
    "assert len(index.get_posting(\"t1\")) == 2\n",
    "assert index.get_posting(\"t3\") == None\n",
    "index.write_to_file(\"data/msmarco_passage/collection_jsonl/text_index.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Index part of the MS MARCO collection\n",
    "\n",
    "Complete the code to process the text and create the index. \n",
    "Note that we are only interested in indexing `docs00.json` file and it takes few minutes to create the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "\n",
    "ind = InvertedIndex()\n",
    "file = \"data/msmarco_passage/collection_jsonl/docs00.json\"\n",
    "index_file = \"data/msmarco_passage/collection_jsonl/tiny_index.txt\"\n",
    "\n",
    "def index(jsonl_file):\n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        for line in f:\n",
    "            doc = json.loads(line)\n",
    "            # =======Your code=======\n",
    "            text = doc['contents']\n",
    "            doc_id = doc['id']\n",
    "            terms = process(text)\n",
    "\n",
    "            for term, count in collections.Counter(terms).items():\n",
    "                ind.add_posting(term, doc_id, count)            \n",
    "            # =======================\n",
    "            \n",
    "index(file)\n",
    "ind.write_to_file(index_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this to test your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(index_file, 'r') as fp:\n",
    "    assert len(fp.readlines()) == 698784\n",
    "\n",
    "assert len(ind.get_posting(\"pressingly\")) == 3\n",
    "assert len(ind.get_posting(\"veada\")) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handing in\n",
    "\n",
    "Hand in both the result file and the filled-in notebook:\n",
    "\n",
    "- The result file should be named STUDENTNUMBER_FIRSTNAME_LASTNAME_tiny_index.txt\n",
    "- The notebook should be named STUDENTNUMBER_FIRSTNAME_LASTNAME_indexing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b333cffad54cf9f22a00fb4710e73f1d60aca41dd0187b9ad1417194137be373"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
